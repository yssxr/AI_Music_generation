# -*- coding: utf-8 -*-
"""Music_Generation_with_Deep_Learning (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wdUhgf2MOd2b7Kk1sH7dG2nFZ7aaom9g
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install music21

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import tensorflow
import numpy
import os
import zipfile
from music21 import instrument, note, stream, chord
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import LSTM,ConvLSTM1D,Flatten,GRU
from tensorflow.keras.layers import BatchNormalization as BatchNorm
from tensorflow.keras.layers import Activation
from music21 import midi
import glob
def noop(input):
  pass
midi.translate.environLocal.warn = noop

with zipfile.ZipFile('/content/drive/MyDrive/dataset.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/data')

folders1=os.listdir('/content/data')

from music21 import converter, instrument, note, chord
notes = []
for file in glob.glob('/content/data/Classical-Piano-Composer-master/midi_songs/*.mid'):
    print(file)
    midi = converter.parse(file)
    notes_to_parse = None
    parts = instrument.partitionByInstrument(midi)
    if parts: # file has instrument parts
        notes_to_parse = parts.parts[0].recurse()
    else: # file has notes in a flat structure
        notes_to_parse = midi.flat.notes
    for element in notes_to_parse:
            #storing pitch of instrument
        if isinstance(element, note.Note):
            notes.append(str(element.pitch))
        elif isinstance(element, chord.Chord):
            notes.append('.'.join(str(n) for n in element.normalOrder))

from keras.utils import np_utils

#Creating Sequence of 100 for each sample and generating sequence of data
sequence_length = 100
n_vocab = len(set(notes))# number of samples are set as vocab
pitchnames = sorted(set(item for item in notes))
note_to_int = dict((note, number) for number, note in enumerate(pitchnames))
#creating input and output sequence 
network_input = []
network_output = []
#addding the input sequence and output sequence from notes with look back of 100
for i in range(0, len(notes) - sequence_length, 1):
    sequence_in = notes[i:i + sequence_length]
    sequence_out = notes[i + sequence_length]
    network_input.append([note_to_int[char] for char in sequence_in])
    network_output.append(note_to_int[sequence_out])
n_patterns = len(network_input)
network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))
network_input = network_input / float(n_vocab)
#one hot encoding the target features
network_output = np_utils.to_categorical(network_output)

"""***LSTM model***"""

#LSTM model
#Creating LSTM model with 1 hidden layer and 3 LSTM layers
model = Sequential()
model.add(LSTM(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        return_sequences=True
    ))
model.add(Dropout(0.3))
model.add(LSTM(512, return_sequences=True)) #LSTM layer
model.add(Dropout(0.3))#dropout layer to control overfitting
model.add(LSTM(256))
model.add(Dense(256))
model.add(Dropout(0.3))#dropout layer to control overfitting
model.add(Dense(n_vocab))
model.add(Activation('softmax'))#output layer
model.compile(loss='categorical_crossentropy', optimizer='adam')

model.fit(network_input, network_output, epochs=100, batch_size=64)

"""***GRU Model***"""

#GRU 
model = Sequential()
model.add(GRU(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        return_sequences=True
    ))
model.add(Dropout(0.3))##dropout layer to control overfitting
model.add(GRU(512, return_sequences=True)) #GRU layer
model.add(Dropout(0.3))#dropout layer to control overfitting
model.add(GRU(256))
model.add(Dense(256))
model.add(Dropout(0.3))#dropout layer to control overfitting
model.add(Dense(n_vocab))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')

"""***LSTM+GRU Model***"""

#LSTM+GRU model
#Creating Combination of LSTM+GRU model for training 
model = Sequential()
model.add(LSTM(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        return_sequences=True
    ))
model.add(Dropout(0.3)) #dropout layer to control overfitting
model.add(GRU(512, return_sequences=True)) #GRU layer
model.add(Dropout(0.3))#dropout layer to control overfitting
model.add(GRU(256))#GRU layer
model.add(Dense(256))#hidden layer
model.add(Dropout(0.3))
model.add(Dense(n_vocab))
model.add(Activation('softmax'))#output layer
model.compile(loss='categorical_crossentropy', optimizer='adam')

model.summary()

from keras.callbacks import ModelCheckpoint

filepath = "/content/logs/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5"    
checkpoint = ModelCheckpoint(
    filepath, monitor='loss', 
    verbose=0,        
    save_best_only=True,        
    mode='min'
)    
callbacks_list = [checkpoint]     
hist=model.fit(network_input, network_output, epochs=100, batch_size=64, callbacks=callbacks_list)# training LSTM+GRU model and saving weights

"""***Generating Part***"""

import pickle
import numpy
from music21 import instrument, note, stream, chord
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import LSTM
from keras.layers import BatchNormalization as BatchNorm
from keras.layers import Activation
#loading notes , the previous information
def generate():
    with open('/content/notes', 'rb') as filepath:
        notes = pickle.load(filepath)
    pitchnames = sorted(set(item for item in notes))
    n_vocab = len(set(notes))
#normalizing the inputs which are randomly generated from distribution
    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)
    model = create_network(normalized_input, n_vocab)
    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)#generating notes based on input submitted (sequence lenght)
    create_midi(prediction_output)

#Preparation of 100 lengh sequence for forecasting with Newly generated data with respect to old data
def prepare_sequences(notes, pitchnames, n_vocab):
    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))

    sequence_length = 100#squence lengh define as per training data
    network_input = []
    output = []
    #creating loop structure to prpeare input and ouput fron extracte features 
    for i in range(0, len(notes) - sequence_length, 1):
        sequence_in = notes[i:i + sequence_length]
        sequence_out = notes[i + sequence_length]
        network_input.append([note_to_int[char] for char in sequence_in])
        output.append(note_to_int[sequence_out])

    n_patterns = len(network_input)#number of pattersn to be defiend
    normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))
    normalized_input = normalized_input / float(n_vocab)

    return (network_input, normalized_input)
#Creating Network and loading Network
def create_network(network_input, n_vocab):
    """ create the structure of the neural network """
    model = Sequential()
    model.add(LSTM(
        512,
        input_shape=(network_input.shape[1], network_input.shape[2]),
        recurrent_dropout=0.3,
        return_sequences=True
    ))
    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.3,))
    model.add(LSTM(512))
    model.add(BatchNorm())
    model.add(Dropout(0.3))
    model.add(Dense(256))
    model.add(Activation('relu'))
    model.add(BatchNorm())
    model.add(Dropout(0.3))
    model.add(Dense(n_vocab))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

    model.load_weights('weights_lstm_gru.hdf5')#loading weights of Networks

    return model

def generate_notes(model, network_input, pitchnames, n_vocab):
    start = numpy.random.randint(0, len(network_input)-1) #Different Music generation after each time you ran

    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))

    pattern = network_input[start]
    prediction_output = []
    for note_index in range(100): #This will control the lengh of generated music  change this number if you want to generate higher duration 
        prediction_input = numpy.reshape(pattern, (1, len(pattern), 1)) 
        prediction_input = prediction_input / float(n_vocab)

        prediction = model.predict(prediction_input, verbose=0)#making prediction on the data

        index = numpy.argmax(prediction)#converting the one hot encoded data to single array
        result = int_to_note[index]
        prediction_output.append(result)

        pattern.append(index)
        pattern = pattern[1:len(pattern)]

    return prediction_output

def create_midi(prediction_output):
    offset = 0
    output_notes = []
    for pattern in prediction_output:
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            #feature matchig of generated music and creatig a reference
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        offset += 0.5

    midi_stream = stream.Stream(output_notes)

    midi_stream.write('midi', fp='test_output.mid') #saving the generated file as mid file

if __name__ == '__main__':
    generate()